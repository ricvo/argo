
# add here few words about what is the purpose of this experiment
# keep only one experiment per file

##############################################################
[
{
"dataName" : "FashionMNIST",
"binary" : 0,
"flip_fraction" : 0.,
"vect" : False  # False if starting with convolutional, True will give the dataset already vectorialized (reshaped -1)
},
{
"model" : "AE.AutoEncoder",

"stochastic" : [1],
"stochastic_noise_param" : [0, 0.01], #0, ,0.00001,0.001,0.1,1
"denoising" : [0],
"rescale" : [0.00001],

"optimizer": [("AdamOptimizer", {"learning_rate" : 0.001,	
					  "beta1": 0.9,
                      			  "beta2":0.999})],

#"grad_clipping" : (None, {}),
"grad_clipping" : ("clip_by_norm", {"value" : 1}),


"cost_function": [("L2", {})
		  ],

"covariance_parameterization" : "softplus", # "exp" or "softplus"

"network_architecture" : [
        {
        "encoder" : [
            ("BatchFlatten", {}, 0),
            ("Linear", {"output_size" : 200}, 1),
            ("Linear", {"output_size" : 200}, 1),
	    ("Linear", {"output_size" : size_h}, 1),
            ],
        "decoder" : [
            ("Linear", {"output_size" : 200}, 1),
            ("Linear", {"output_size" : 200}, 1),
            ("LogitNormalDiagonal", {"module_tuple" : ("LinearWN", {"use_weight_norm" : False})}, 0)
	    #("GaussianDiagonalZeroOne", {"module_tuple" : ("LinearWN", {"use_weight_norm" : False})}, 0)
            ]
        }
	for size_h in [64, 128]
	],

#"weights_reg" : [("contrib.layers.l2_regularizer", {"scale" : 0.5})],
#"bias_reg" : [("contrib.layers.l2_regularizer",    {"scale" : 0.5})],

"weights_reg" : [None],
"bias_reg" :    [None],


"weights_init" : [("contrib.layers.xavier_initializer",{})],  # !!! truncated normal
"bias_init" : [("constant_initializer", {'value' : 0.1})],
#	       ("constant_initializer", {'value' : 0.01})],

"activation" : ["relu"],
"epochs" : 500,

},
{
"check_ops" : 0,

# choose steps or epochs
"time_reference" : "epochs",

# how often to log stats (txt) and save summaries (related to the stats)
"stats_period" : 1,

# choose to save the model every n steps
"save_model" : 1,

"save_model_period" : 10,

# how often to save other specific summaries
"save_summaries" : 1,

"save_summaries_period" : 10,

# skips the first k stats for the plot
"plot_offset" : 1,

"GradientsHook" : {"period" : 10},


"ImagesInputHook" : {"period" : 100,
                    "how_many" : 18,
                    "n_images_columns" : 6},

"VAEImageReconstructHook" : {"period" : 100,
                             "n_images_columns" : 6,
                             "images_indexes" : {
                                                 "train" : [0,100,200,300,400,500],
                                                 "validation" : [0,100,200,300,400,500],
                                                 },
                            },

"ImageGenerateHook" : {"period" : 100,
                       "n_images_columns" : 6,
                       "n_gen_samples" : 18
                       },

"TwoDimPCALatentVariablesHook" : {"period" : 50,
                                  },

"PCALatentVariablesHook" : {"period" : 50,
                             },


#"LogpImportanceSamplingHook" : {"period" : 100,
#		       	        "n_samples" : [1,10],
#		     		"batch_size" : 1000,
#				"repetitions" : 3
#                       	       },



"dirName" : "/data1", #"temp",


"seed" : 0,
"runs" : 1,

"nodes" : [{"used_GPUs" : {3},
            "cores_per_GPU" : 2,
	    "IP": "localhost"   #  num_consumers = multiprocessing.cpu_count() * 2
	   }
	   ],


####### not used after this line

"n_epoch_log" : 1,
"n_epoch_plot" : 500,

# log norm and log
"log_gradient" : 0,#1,
"n_epoch_log_gradient" : 200,

# needs vae.sample()
"generate_images": 0,
"n_generate_images_rows": 2,
"n_generate_images_columns": 20,
"n_epoch_generate_images" : 250,

# needs x_train[subset, x_validate[subset, vae.regenerate()
"regenerate_images": 0,
"n_regenerate_images_rows": 2,
"n_regenerate_images_columns": 20,
"n_epoch_regenerate_images" : 250,

# needs x_train, x_validate, vae.encode()
"log_latent_vars_pca" : 0,
"n_epoch_log_latent_vars_pca_eigenvals" : 100,

# needs x_train[subset], x_validate[subset], 2 nodes "Distribution" of the latent
"log_latent_vars_model" : 0,
"n_epoch_log_latent_vars_model" : 25,
"log_latent_vars_model_points_train" : [10,20,30,40,50,100,200,300,400,500],
"log_latent_vars_model_points_test" : [10,20,30,40,50,100,200,300,400,500],

# needs x_train[subset], x_validate[subset], 2 nodes "Distribution" of the visible
"log_visible_vars_model" : 0,
"n_epoch_log_visible_vars_model" : 25,
"log_visible_vars_model_points_train" : [10,20,30,40,50,100,200,300,400,500],
"log_visible_vars_model_points_test" : [10,20,30,40,50,100,200,300,400,500],

# needs x_train[subset], x_validate[subset], vae.regenerate()
"log_repeated_reconstructions" : 0,
"n_epoch_log_repeated_reconstruction" : 25,
"n_repeated_reconstructions" : 100,
"log_repeated_reconstruction_points_train" : [10,20,30,40,50,100,200,300,400,500],
"log_repeated_reconstruction_points_test" : [10,20,30,40,50,100,200,300,400,500],

# needs pairs from x_train[subset], paris from x_validate[subset], 2 nodes "Distribution" of the latent, vae.decode() (attached to a feedable)
"log_latent_lin_interpolate" : 0,#1
"n_epoch_log_latent_lin_interpolate" : 100,
"lin_interpolate_couples" : [[10,20],[20,30]],
"n_interpolate_steps" : 20,

# needs x_train, y_train, x_validate, y_valudate, 2 nodes "Distribution" of the latent
"log_latent_vars_classification" : 0,
"n_epoch_log_latent_vars_classification" : 50,
"plot_misclassified_images" : 1,
"n_misclassified_images" : 100,

# needs x_train, x_validate, vae.encode()
"log_latent_vars_corr" : 0,
"n_epoch_log_latent_vars_corr" : 100,

# needs x_train, x_validate, vae.regenerate(), needs to pass a placefolder for the number of samples (using the placeho,der)
"log_estimate_log_p" : 0,
"n_epoch_log_estimate_log_p" : 100,
#"estimate_log_p_samples" : [1,10,50,200,1000],#,5000],
"estimate_log_p_samples" : [1,10,100,500,1000],#,1000,5000],  #,200,500,1000,2000,5000,10000
"estimate_log_p_batch_size" : 1000,
"estimate_log_p_repetitions" : 1,

# needs x_train, x_validate, vae.regenerate(), needs to pass a placefolder for the number of samples (using the placeho,der)
"log_estimate_function" : 0,

}
]
