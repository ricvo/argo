# add here few words about what is the purpose of this experiment
# keep only one experiment per file

##############################################################
[
{
"dataName" : "CMB",

# ironman 
#"data_dir" : '/ssd_data/CMB/hector/FullMap/New2019/Dataset-256-20-Lens-tools-01noise/omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0+patch_s20+pic_s256/',

#captamerica
"data_dir" : '/ssd_data/CMB/Dataset-256-20-Lens-tools-01noise/omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0+patch_s20+pic_s256/',

# wonderwoman 
#"data_dir" : '/ssd_data/CMB/omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0+patch_s20+pic_s256/',

"vect" : False,       # False if starting with convolutional, True will give the dataset already vectorialized (reshaped -1)
"conf_dict" : ['omega_cdm', 'A_s']
},
{

"model" : ["VAE.VAE"], #"VAE_IAF.VAE_IAF"

"stochastic" : [1],
"stochastic_noise_param" : [0, 0.03], #0, ,0.00001,0.001,0.1,1
"denoising" : [0],

"batch_size_train" : [16,64],
"batch_size_eval" : [16],


"optimizer": [("AdamOptimizer", {"learning_rate" : 0.001,
					  "beta1": 0.9,
                      			  "beta2":0.999})],

"grad_clipping" : ("clip_by_global_norm", {"value" : 300}),


"cost_function": [
                  ("ELBO", {"beta" : 1.0,
		            "warm_up_method" : ("warm_up", {"epoch" : 5})})
		  ],

"samples" : [1, 5], # 1 or more
"covariance_parameterization" : "softplus", # "exp" or "softplus"

# see https://github.com/hwalsuklee/tensorflow-generative-model-collections/blob/master/VAE.py
# and https://github.com/hwalsuklee/tensorflow-generative-model-collections/blob/master/ops.py


#"network_architecture" : [{
#        "encoder" : [
#	    ("Conv2D", {"output_channels" : 64, "kernel_shape" : 4, "stride" : 2}, 1),
#	    ("Conv2D", {"output_channels" : 128, "kernel_shape" : 4, "stride" : 2}, 0),
#	    ("BatchNorm", {"offset" : 1, "scale" : 1, "decay_rate" : 0.9}, 1),
#	    ("BatchFlatten", {}, 0),
#	    ("Linear", {"output_size" : 256}, 0),
#	    ("BatchNorm", {"offset" : 1, "scale" : 1, "decay_rate" : 0.9}, 1),
#    	("GaussianDiagonal", {"output_size" : 50, "module_tuple" : ("Linear", {})}, 0)
#        #("GaussianDiagonal", {"output_size" : 1024,
#        #                      "module_tuple" : ("Linear", {}),
#        #                      "contractive_regularizer" : ("standard_contractive_regularizer",
#        #                                                    {"scale_mean" : 0.001,
#        #                                                    "scale_covariance" : 0.001,
#        #                                                    "norm" : 2}),
#		#		              },
#		#		              0)
#        ],
# 
#        "decoder" : [
#            ("Linear", {"output_size" : 256}, 0),
#	    ("BatchNorm", {"offset" : 1, "scale" : 1, "decay_rate" : 0.9}, 1),
#	    ("Linear", {"output_size" : 128 * 64 * 64}, 0),
#	    ("BatchNorm", {"offset" : 1, "scale" : 1, "decay_rate" : 0.9}, 1),
#            ("BatchReshape", {"shape" : (64, 64, 128)}, 0),
#            ("Conv2DTranspose", {"output_channels" : 64, "output_shape" : [128, 128], "kernel_shape" : 4, "stride" : 2}, 0),
#	    ("BatchNorm", {"offset" : 1, "scale" : 1, "decay_rate" : 0.9}, 1),
#            ("Conv2DTranspose", {"output_channels" : 1, "output_shape" : [256, 256], "kernel_shape" : 4, "stride" : 2}, 1),
#	    #("BatchFlatten", {}, 0),
#    	    #("LogitNormalDiagonal", {"module_tuple" : ("Linear", {})}, 0)
#	    #("GaussianDiagonalPlusMinusOne", {"module_tuple" : ("Conv2D", {"kernel_shape" : 3})}, 0)
#	    ("LogitNormalDiagonalPlusMinusOne", {"module_tuple" : ("Conv2D", {"kernel_shape" : 3}),
#	    					 "clip_value" : 0.0001}, 0)
#           ]
#	}
#	],


"network_architecture" : [{
        "encoder" : [
            ("ConvNet2D", {"output_channels": [8, 16, 32, 64, 128],
			   "strides" : [2, 1, 2, 1, 2],
			   "paddings" : ["SAME"],
			   "kernel_shapes" : [[3, 3]]},  1),
	    ("BatchFlatten", {}, 0),
            ("GaussianDiagonal", {"output_size" : lat_var,
                                  "module_tuple" : ("LinearWN", {"use_weight_norm" : False}),
				  "minimal_covariance": 0.001
                                  }, 0)],
 
        "decoder" : [
		  ("Linear", {"output_size" : 64 * 64 * 64}, 1),
		  ("BatchReshape", {"shape" : (64, 64, 64)}, 0),
                  ("ConvNet2DTranspose", {"output_channels": [32, 1],
	                                  "output_shapes" : [[128, 128], [256, 256]],
				          "strides" : [2],
				          "paddings" : ["SAME"],
				          "kernel_shapes" : [[3, 3]]},      0),
		  #("BatchFlatten", {}, 0),
                  ("LogitNormalDiagonalPlusMinusOne", {"module_tuple" : ("Conv2D", {"kernel_shape" : 3}),
		  				      "clip_value" : 0.0001
                                          }, 0)
            ]
	} for lat_var in [50]],



"weights_reg" : [("contrib.layers.l2_regularizer", {"scale" : 0.0001})],
"bias_reg" : [("contrib.layers.l2_regularizer",    {"scale" : 0.0001})],

#"weights_reg" : [None],
#"bias_reg" :    [None],


"weights_init" : [("contrib.layers.xavier_initializer", {})], # ("truncated_normal_initializer", {"stddev" : 0.02})],  # !!! truncated normal
"bias_init" : [("constant_initializer", {'value' : 0.1})], #   ("constant_initializer", {'value' : 0.0})],

"activation" : ["elu"],  #"elu"
"epochs" : 500,

},
{
"check_ops" : 0,

# choose steps or epochs
"time_reference" : "epochs",

# how often to log stats (txt) and save summaries (related to the stats)
"stats_period" : 1,

# choose to save the model every n steps
"save_model" : 1,
"save_model_period" : 50,

# how often to save other specific summaries
"save_summaries" : 0,
"save_summaries_period" : 10,

# skips the first k stats for the plot
"plot_offset" : 0,


"GradientsHook" : {"period" : 5},

"ImagesInputHook" : {"period" : 15,
                     "how_many" : 18,
                     "n_images_columns" : 6},

"ImagesReconstructHook" : {"period" : 5,
                           "n_images_columns" : 6,
                           "images_indexes" : {
                                                 "train" : [0,100,200,300,400,500],
                                                 "validation" : [0,100,200,300,400,500],
                                                 },
                            },

"ImagesGenerateHook" : {"period" : 5,
                        "n_images_columns" : 6,
                        "n_gen_samples" : 18
                       },

#"TwoDimPCALatentVariablesHook" : {"period" : 50,
#                                  },

"PCALatentVariablesHook" : {"period" : 50,
                             },


"ImportanceSamplingHook" : [{"period" : 10,
                             "n_samples" : [1, 10],
                             "batch_size" : 10,
                             "repetitions" : 2
                       	   }],

#"FrechetInceptionDistanceHook" : [{"period" : 10,
#				   "n_batches" : 1,
#				  },
#				  # since it takes a lot of time for all images, I compute with all images only at the end of training
#				  {"period" : 10,
#				   "n_batches" : 10,
#				  },
#				  {"period" : 10,
#				   "n_batches" : 1,
#				   "pb" : "/home/luigi/prediction/natural/MNIST-c-st0/FF-cCE-st0-stp0-re0.0001-bs32-trGD_lr0.05-cNo-nD200_D200_D10-cpS-aR-wix-bic0.1-r0/saved_models/output_graph.pb",
#				   "id" : "MNIST",
#				   "input_tensor" : "inputs:0",
#				   "output_tensor" : "logits:0"
#				  },
#				  {"period" : 10,
#				   "n_batches" : 10,
#				   "pb" : "/home/luigi/prediction/natural/MNIST-c-st0/FF-cCE-st0-stp0-re0.0001-bs32-trGD_lr0.05-cNo-nD200_D200_D10-cpS-aR-wix-bic0.1-r0/saved_models/output_graph.pb",
#				   "id" : "MNIST",			   
#				   "input_tensor" : "inputs:0",	
#				   "output_tensor" : "logits:0"
#				  }],


#"VAELinearInterpolationHook" : {"period" : 10,
#                               "n_images" : 15,
#                               "images_indexes" : {
#                                                 "train" : [(0,50),
#						            (100,230),
#							    (200,790),
#							    (300,600),
#							    (400,1000)],
#                                                 "validation" : [(0,50),
#						                 (100,230),
#							         (200,790),
#							         (300,600),
#							         (400,1000)],
#                                                 },
#                            },


#"LatentVarsClassificationHook" : {"period" : 10,
#			          "learning_rate" : 0.001,
#                                  "steps" : 30000,
#				  "repetitions" : 5
#                       	      	 },



#"plot_misclassified_images" : 1,
#"n_misclassified_images" : 100,


"dirName" : "temp",

"seed" : 0,
"runs" : 1,

"nodes" : [{"used_GPUs" : {3},
            "cores_per_GPU" : 1,

	    "IP": "localhost"   #  num_consumers = multiprocessing.cpu_count() * 2
	   }
	   ],

}
]