[
{
"dataName" : "CMB_multifilters",
'data_dir': '/ssd_data/CMB/Dataset21_cm_Total/ION_Tvir_MIN_HII_EFF_FACTOR_sigma_8_omega_m-uniform-iz6-fz12-samz20-pxl128-sMpc192/',##iron 21
#"data_dir" : "/ssd_data/CMB/Polar/omega_b_omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0-cod_hp+patch_s20+pic_s256/",#POL_CAPTAM
#"data_dir" : '/ssd_data/CMB/Dataset-256-20-Lens-tools-01noise/omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0+patch_s20+pic_s256/',
#"data_dir" :'/ssd_data/CMB/Dataset-256-20-Lens-tools-01noise/omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0+patch_s20+pic_s256/',
#"data_dir" :'/ssd_data/CMB/omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0+patch_s20+pic_s256/', 
#"data_dir"  :  '/ssd_data/CMB/omega_b_omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0-cod_lt+patch_s20+pic_s256/', #WM
#"data_dir" :  '/ssd_data/CMB/omega_b_omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0-cod_lt+patch_s20+pic_s256/',#capmerica
#"data_dir" :  '/ssd_data/CMB/hector/three_params_July/omega_b_omega_cdm_A_s-uniform-pppr_rot0-pppr_eq1-pppr_lat1-aug0-cod_lt+patch_s20+pic_s256/',#iroman

"fraction_dataset" : 100,   #(10,20,50,100); 100% is the total dataset

"parameters" : [['sigma_8' ,'omega_m' ,'HII_EFF_FACTOR','ION_Tvir_MIN']],
},


{
"stochastic" : 0,
"stochastic_noise_param" : 0,
#"dtype" : "float32",            #datatype for weights, use float32
"model" : "Prediction.RegressionModel",      # it can be classificiation or regression

"network" : "CMBNetwork",

#deterministic prediction
#"cost_function": [("MSE", {})],
# #stochastic prediction
"cost_function": [("Likelihood", {'use_alpha':True, 'alpha_parameter':alpp, "alpha_samples":sam})for sam in [1,10] for alpp in [0]], ## use 1, if use_alpha is False
"optimizer":  [ ("AdamOptimizer", {"learning_rate" :

                                        (1e-9,
                                        "exponential_decay", {"learning_rate" : 1e-5,
                                                              "decay_steps" : dstep,
                                                               "staircase" : True,
                                                              "decay_rate" : 0.9,
                                                             }
                                         ),
                                  "beta1" : 0.9,
                       			  "beta2" : 0.999}) for dstep in [3000] ] ,


"grad_clipping" : ("clip_by_global_norm", {"value" : 100}),
#"grad_clipping" : ("clip_by_norm", {"value" : 1}),
#"grad_clipping" : (None, {}),

#"grad_clipping" : {"method" : "global", "value" : 3.},

"batch_size_train" : [16],
"batch_size_eval" : [16],
"batch_size_test" : [16],

"network_architecture" : [("Vgg_Bernoulli", {"filters": [32, 32, 32, 32, 64],
                                            "drop_connect" : dc,
                                            "prob_drop" : pd,
                                            "bn_renormalization":bnr,
                                            "bn_momentum" : bnm,
                                            "aleatoric_layer" : ("MultivariateNormalTriL", {"minimal_covariance": 1e-4})
                                           }
                           )
                           for dc in [False]
                           for bnr in [False]

                           for pd in [0.01,0.1]
                           for bnm in [0.99] #, 0.97]

                          ],

"weights_reg" : [("contrib.layers.l2_regularizer", {"scale" : scale }) for scale in [1e-5]],
"bias_reg" : [("contrib.layers.l2_regularizer",    {"scale" : scale }) for scale in [0.0001]],

"activation" : ["leaky_relu"], # "elu"  you can also try "leaky_relu"
"weights_init" : [("glorot_normal_initializer", {})],

"bias_init" : [("constant_initializer", {'value' : bi}) for bi in [1.]],

"epochs" : 161,                     # number of epochs


},
{
"check_ops" : 0,                # for debug purposes

"time_reference" : "epochs",
"stats_period" : 1,

"save_model" : 1,		# if 1, the model is savedevery X epocs
"save_model_period" : 20,      #0.1,

"plot_offset" : 3,

"save_summaries" : 1,
"save_summaries_period" : 5,

#"GradientsHook" : {"period" : 100},

"CorrelationHook" : {"period" : 30},

"ImagesInputHook" : {"period" : 1000,
                    "until" : 30,
                    "how_many" : 6,
                    "n_images_columns" : 6},

"MCDropoutHook" : {"period" : 160,
                     "n_batches" : 80,
                     "posterior_samples" : 3500},
#"MCDropoutHook_alpha" : {"period" : 80,
#                     "n_batches" : 150,
#                     "posterior_samples" : 3500,
#                      },



"dirName" : "/data1/mcmc/ICLR/",
	    			# experiments should be saved in /data2/XXX or /data1/XXX


"seed" : 0,			# do not change
"runs" : 1,			# number of run the algorithm is executed
# set pool size for GPU



"nodes" : [{"used_GPUs" : [1,2], #{0},

            "cores_per_GPU" : 1,
            "IP": "localhost"   #  num_consumers = multiprocessing.cpu_count() * 2
            }
            ]
}
]
