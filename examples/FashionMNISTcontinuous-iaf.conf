
# add here few words about what is the purpose of this experiment
# keep only one experiment per file

##############################################################
[
{
"dataName" : "FashionMNIST",
"vect" : False  # False if starting with convolutional, True will give the dataset already vectorialized (reshaped -1)
},
{
"model" : "VAE_IAF.VAE_IAF",
"stochastic" : [0], # 1],
"stochastic_noise_param" : [0], #[0.03], #0, ,0.00001,0.001,0.1,1
"denoising" : [0], # 1],
"rescale" : [0.001],

"optimizer": [("AdamOptimizer", {"learning_rate" : 0.002,
	                         "beta1": 0.9,
                      		 "beta2":0.999})],

"grad_clipping" : ("clip_by_global_norm", {"value" : 1.0}), # NB not implemented in the filename

"cost_function": [#("IELBO", {"beta" : 1.0, "h" : 0.01, "normalize" : 1}),
                  ("ELBO_IAF", {"beta" : beta,
		                #"warm_up_method" : ("warm_up", {"epoch" : 5}),
                                "kl_min" : klm})
        		  #{"cost" : "renyi", "beta" : 1.0, "alpha" : 0.9},
        		  for beta in [1] for klm in [0.1]
                  ],

#"samples" : [10], # 1 or more
#"covariance_parameterization" : "softplus", # "exp" or "softplus"

"batch_size_train" : 32,
"batch_size_eval" : 32,

"network_architecture" : [{
          "z_channels" : 32, # Size of z variables.
          "h_channels" : 160, # NB it must be a multiple of z_size
          "depth" : 1,  # Number of downsampling blocks.
          "num_blocks" : b,  # Number of resnet blocks for each downsampling layer.
          "w_inc" : 0.1, # inception weight "t" is for train
          "nf" : nf, # number of flows for each layer
          "df" : df, # depth of each flow (how many layers to get mu and sigma)
          "context_flow" : cf, # true or false, if the flow depends on the context (x and z) or not
          "k" : k,  # Number of samples for IS objective.
          "stochastic_visible" : ("LogisticDiagonalZeroOne", {
                                                "module_tuple" : ("Conv2DWN", {"kernel_shape" : [3,3],
                                                                      "use_weight_norm" : False}),
                                                "scalar_covariance" : sc,
                                                "zero_one_method" : "sigmoid"
                                              })
                } for df in [2, 4] for b in [2, 5, 10, 20] for cf in [False] for k in [1] for nf in [1, 3, 5] for sc in [True, 0.1, 0.01]
    ],
#for df in [2, 4, 6] for b in [2, 5] for cf in [True, False] for k in [1] for nf in [1, 3, 5] for sc in [True, 0.1, 0.01]

"epochs" : 200,

},
{
"check_ops" : 0,

# choose steps or epochs
"time_reference" : "epochs",

# how often to log stats (txt) and save summaries (related to the stats)
"stats_period" : 1,

# choose to save the model every n steps
"save_model" : 1,
"save_model_period" : 50,

# how often to save other specific summaries
"save_summaries" : 0,
"save_summaries_period" : 10,

# skips the first k stats for the plot
"plot_offset" : 1,

#
#"ImagesInputHook" : {"period" : 25,
#                    "how_many" : 18,
#                    "n_images_columns" : 6},
#

"ImagesReconstructHook" : {"period" : 20,
                           "n_images_columns" : 6,
                           "images_indexes" : {
                                               "train" : [0,100,200,300,400,500],
                                               "validation" : [0,100,200,300,400,500],
                                               },
                           },
#                                                "train" : [0,100,200,300,400,500,600,700,800,900,1000,1100],
#                                                "validation" : [0,100,200,300,400,500,600,700,800,900,1000,1100],
						 
"ImagesGenerateHook" : {"period" : 20,
                        "n_images_columns" : 6,
                        "n_gen_samples" : 18
                        },


"GradientsHook" : {"period" : 10},


#"VAELinearInterpolationHook" : {"period" : 10,
#                               "n_images" : 15,
#                               "images_indexes" : {
#                                                 "train" : [(0,50),
#						            (100,230),
#							    (200,790),
#							    (300,600),
#							    (400,1000)],
#                                                "validation" : [(0,50),
#						                 (100,230),
#							         (200,790),
#							         (300,600),
#							         (400,1000)],
#                                                 },
#                            },


#"LogpImportanceSamplingHook" : {"period" : 100,
#		       	        "n_samples" : [1,10],
#		     		"batch_size" : 1000,
#				"repetitions" : 3
#                       	       },


"dirName" : "temp",

"seed" : 0,
"runs" : 1,

"nodes" : [{"used_GPUs" : {2,3}, #{0,1,2,3},
            "cores_per_GPU" : 2,
            "IP": "localhost"   #  num_consumers = multiprocessing.cpu_count() * 2
            }
            ]


}
]
