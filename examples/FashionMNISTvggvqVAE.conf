# add here few words about what is the purpose of this experiment
# keep only one experiment per file

##############################################################
[
{
"dataName" :  "FashionMNIST" #   "FashionMNIST" # "CIFAR10"
},
{

"model" : ["VQVAE.VQVAE"], #"VAE_IAF.VAE_IAF"

"cost_function": [
                  ("VQELBO", {
                                "use_kl" : False,
                                "beta" : 1.0,
                                "warm_up_method" : ("warm_up", {"epoch" : 50})
                                })
		  ],

"network_architecture" : [{

        "encoder" : [
            ("VGGBlock", {"channels" : 32, "kernel_shape" : 3, "prob_drop": 0.1}, 0),
            ("VGGBlock", {"channels" : 64, "kernel_shape" : 3, "prob_drop": 0.1}, 0), #'linear_last' : 512
        ],

        "vq" : {"pre" : prelayer,
                "embedding_dim" : lsize,
                "num_embeddings": 512,
                "commitment_cost" : 0.25,
                "latent_channels" : 1,
                "prior" : "fixed", #"train"
        },

        "decoder" : [
            ("ConvDec", {
                        #"linear_first" : {"sizes" : [128 * 7 * 7], "reshape" : (7, 7, 128)},
                        "channels" : dec_channels,
                        "kernel_shape" : 3,
                        "final_activation" : True
                        },
                        0
             ),
             output_distribution
         ]
     }

	    for lsize in [64] #, 64]
	    for prelayer in ["Conv2D"] # "Linear",
	    for dec_channels in [[64, 64, 32, 32]] #, [64, 64, 32, 32]]

	    for rectuple in [
                        ("Conv2D", {"kernel_shape" : 3}),
#                         ("Linear", {})
                        ]
        for mincov in [1e-5]
	    for output_distribution in [
#                                    ("LogitNormalDiagonalPlusMinusOne", {"module_tuple" : rectuple,
#                                                                         "minimal_covariance": mincov,
#                                                                         "clip_value" : 1e-7}, 0),
                                    ("GaussianDiagonalPlusMinusOne", {"module_tuple" : rectuple,
                                                                         "minimal_covariance": mincov}, 0)
                                    ]
    ],

#"covariance_parameterization" : "softplus", # "exp" or "softplus"


"stochastic" : [2],
"stochastic_noise_param" : [0.1], #0, ,0.00001,0.001,0.1,1
"denoising" : 1,


"batch_size_train" : [16],
"batch_size_eval" : [16],


"optimizer":  [ ("AdamOptimizer", {"learning_rate" : lr_spec,
                                  "beta1" : 0.9,
                       			  "beta2" : 0.999})
                   for lr_spec in [ (mlr,
                                        "exponential_decay", {"learning_rate" : ilr,
                                                              "decay_steps" : ds, # total train samples: TOT. TOT/BATCH_SIZE = SE steps per epoch
                                                              "decay_rate" : 0.9,
                                                              "staircase" : True
                                                             }
                                         ) for mlr, ilr, ds in [(1e-5, 1e-3, 20000)] #[(1e-3, 2000), (1e-4, 3000)]
                                    ] + [1e-4]
              ],

"grad_clipping" : ("clip_by_global_norm", {"value" : 1e4}),

# "samples" : [10], # 1 or more


"weights_reg" : [("contrib.layers.l2_regularizer", {"scale" : 1e-4})],
"bias_reg" : [("contrib.layers.l2_regularizer",    {"scale" : 1e-4})],

"weights_init" : [("contrib.layers.xavier_initializer", {})], # ("truncated_normal_initializer", {"stddev" : 0.02})],  # !!! truncated normal
"bias_init" : [("constant_initializer", {'value' : 0.1})], #   ("constant_initializer", {'value' : 0.0})],

"activation" : ["relu"],  #"relu"
"epochs" : 300,

},
{
"check_ops" : 0,

# choose steps or epochs
"time_reference" : "epochs",

# how often to log stats (txt) and save summaries (related to the stats)
"stats_period" : 1,

# choose to save the model every n steps
"save_model" : 1,
"save_model_period" : 20,
"save_max_to_keep" : 5,

# how often to save other specific summaries
"save_summaries" : 0,
"save_summaries_period" : 10,

# skips the first k stats for the plot
"plot_offset" : 10,


"GradientsHook" : {"period" : 10},

"ImagesInputHook" : {"period" : 1,
                     "how_many" : 12,
                     "n_images_columns" : 6,
                     "until" : 2},

"ImagesReconstructHook" : {"period" : 10,
                           "n_images_columns" : 12,
                           "images_indexes" : {
                                                 "train" : [0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, 525, 550, 575],
                                                 "validation" : [0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, 525, 550, 575],
                                                 },
                            },

"ImagesGenerateHook" : {"period" : 10,
                        "n_images_columns" : 12,
                        "n_gen_samples" : 36
                       },


"dirName" : "/data3/fashionvggdec/vqvae",

"seed" : 0,
"runs" : 1,

"nodes" : [{"used_GPUs" : [4,5],
            "cores_per_GPU" : 1,
	    "IP": "localhost"   #  num_consumers = multiprocessing.cpu_count() * 2
	   }
	   ],

}
]
