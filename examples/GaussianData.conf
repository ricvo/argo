# add here few words about what is the purpose of this experiment
# keep only one experiment per file

##############################################################
[
{
"dataName" : "syn_gauss",
"binary" : 0,
"stochastic" : 0,
"stochastic_noise_param" : 0,
"obs" : [0],
"synthetic" : 1,
"n_samples_train" : 5000,
"n_samples_test" : 1000,
"input_size" : 50,
"real_latent_size" : 10,
"warm_up_method" : 0,

"epsilon" : 0,
"epsilon_obs" : 0,

#"cost_function": [{"cost" : 0}, #KL divergence (standard VAE bound)
#		  {"cost" : 1, "K" : 10}, #KL divergence with IS (from Variational with Monte Carlo objectives)
#		  {"cost" : 1, "K" : 20}, #KL divergence with IS (from Variational with Monte Carlo objectives)  
#		  {"cost" : 2, "alpha": 0.5}, # Renyi divergence bound
#		  {"cost" : 2, "alpha" : 0.9, "K" : 10}, #Renyi divergence with IS from WS paper, which generalizes the Renyi paper 
#		  {"cost" : 2, "alpha" : 0.9, "K" : 20} #Renyi divergence with IS from WS paper, which generalizes the Renyi paper
#		  ],
"cost_function": [{"cost" : 0, "alpha" : 0.1}],
                  #{"cost" : 2, "alpha" : 0.1},
                  #{"cost" : 2, "alpha" : 0.9}],

"learning_rate" : [0.001],
"samples" : [10],
"imp_samples" : [1000], 
"bit_flip" : [0],
"drop_out" : [0],
"latent_noise" : [0],
"batch_size" : [100],
#"hidden_variables_size" : [20],
"network_architecture" : [{"type" : "FF",
                          "n_hidden_layers" : 0,
                          "hidden_layers_size" : [200, 200]}],

"latent_variables_size" : [10], 
"regularizer" : [0],
"weights_init" : ["normal_init"],
"bias_init_value": [0.1],
"k" : [0],
"transfer_fct" : ["relu"],
"epochs" : 50,
# not used anymore, to run on cpu, set used_GPUs = {-1} and then run single
#cpu : 1
},
{
"check_ops" : 1,
#"log_txt" : 0,

"save_model" : 0,
"n_epoch_save_model" : 100,

"log_gradient" : 0,
"n_epoch_log_gradient" : 1,

"generate_images": 1,
"n_generate_images": 100,
"n_epoch_generate_images" : 100,

"regenerate_images": 1,
"n_regenerate_images": 100,
"n_epoch_regenerate_images" : 100,

"log_latent_vars_model" : 0,
"n_epoch_log_latent_vars_model" : 100,
"log_latent_vars_model_points" : [10],

"log_latent_vars_pca" : 1,
"n_epoch_log_latent_vars_pca_eigenvals" : 10,

"log_latent_vars_corr" : 0, 
"n_epoch_log_latent_vars_corr" : 100,


"log_latent_lin_interpolate" : 0,
"n_epoch_log_latent_lin_interpolate" : 1,
"start_lin_interpolate" : 10000,
"end_lin_interpolate" : 2000,
"n_interpolate_steps" : 20,

"log_latent_vars_classification" : 0,
"n_epoch_log_latent_vars_classification" : 1,
"plot_misclassified_images" : 1,
"n_misclassified_images" : 100,



"log_tf" : 0,
"verbose" : 1,

"dirName" : "./testMeGauss",

"seed" : 0,
"runs" : 3,
# set pool size for GPU
"used_GPUs" : {0},
"cores_per_GPU" : 1   #  num_consumers = multiprocessing.cpu_count() * 2
}
]
