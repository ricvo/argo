# add here few words about what is the purpose of this experiment
# keep only one experiment per file

##############################################################
[
{
"dataName" : "OMNIGLOT",
"binary" : 1,
"stochastic" : 1,
},
{
"synthetic" : 0,
"stochastic" : 1,
"stochastic_noise_param" : [0.1],
"obs" : [0],

"warm_up_method" : 0,

"epsilon" : 0,
"epsilon_obs" : 0,

"grad_clipping" : ("clip_by_global_norm", {"value" : 3}), # NB not implemented in the filename

#"cost_function": [{"cost" : 0}, #KL divergence (standard VAE bound)
#		  {"cost" : 1, "K" : 10}, #KL divergence with IS (from Variational with Monte Carlo objectives)
#		  {"cost" : 1, "K" : 20}, #KL divergence with IS (from Variational with Monte Carlo objectives)
#		  {"cost" : 2, "alpha" : 0.9, "K" : 10}, #Renyi divergence with IS from WS paper, which generalizes the Renyi paper
#		  {"cost" : 2, "alpha" : 0.9, "K" : 20} #Renyi divergence with IS from WS paper, which generalizes the Renyi paper
# 		  ],

"cost_function": [{"cost" : 0, "lambda": 1.0}], #KL divergence (standard VAE bound)

"learning_rate" : [0.001],
"samples" : [1],
"imp_samples" : [200],
"bit_flip" : [0],
"drop_out" : [0],
"latent_noise" : [0],
"batch_size" : [100],
#"hidden_variables_size" : [200],
"network_architecture" : [{"type" : "FF",
                          "n_hidden_layers" : 2,
                          "hidden_layers_size" : [200, 200]},
			  {"type" : "FF",
                          "n_hidden_layers" : 3,
                          "hidden_layers_size" : [400, 300, 200]}],
"latent_variables_size" : [15, 20, 25, 30],
"regularizer" : [0],
"bias_init_value" : [0.1, 0.01],
"weights_init" : ["xavier_init"],
"k" : [0],
"transfer_fct" : ["relu","elu"],
"epochs" : 2000,
# not used anymore, to run on cpu, set used_GPUs = {-1} and then run single
#cpu : 1
},
{
"check_ops" : 0,
#"log_txt" : 0,

"n_epoch_log" : 1,

"save_model" : 1,
"n_epoch_save_model" : 200,

"log_gradient" : 0,
"n_epoch_log_gradient" : 100,

"generate_images": 1,
"n_generate_images": 100,
"n_epoch_generate_images" : 100,

"regenerate_images": 1,
"n_regenerate_images": 100,
"n_epoch_regenerate_images" : 100,


"log_latent_vars_model" : 1,
"n_epoch_log_latent_vars_model" : 100,
"log_latent_vars_model_points" : [10],

"log_latent_vars_pca" : 1,
"n_epoch_log_latent_vars_pca_eigenvals" : 100,

"log_latent_vars_corr" : 1,
"n_epoch_log_latent_vars_corr" : 100,

"log_latent_lin_interpolate" : 1,
"n_epoch_log_latent_lin_interpolate" : 100,
#"start_lin_interpolate" : 10000,
#"end_lin_interpolate" : 2000,
"lin_interpolate_couples" : [[10,20],[20,30],[40,50],[10,30]],
"n_interpolate_steps" : 20,

"log_latent_vars_classification" : 1,
"n_epoch_log_latent_vars_classification" : 100,
"plot_misclassified_images" : 1,
"n_misclassified_images" : 100,

"log_estimate_log_p" : 1,
"n_epoch_log_estimate_log_p" : 500,
#"estimate_log_p_samples" : [1,10,50,200,1000],#,5000],
"estimate_log_p_samples" : [1,10,100,200,500,1000,2000,5000,10000],#,1000,5000],
"estimate_log_p_batch_size" : 1000,
"estimate_log_p_repetitions" : 1,

"log_tf" : 0,
"verbose" : 1,

"launcher": "vae.core.VAELauncher.VAELauncher",

# this should not be changed, if you need, make a new copy of this file and save it in experiments
"dirName" : "/data2/OMNIGLOT",

"seed" : 0,
"runs" : 3,

"nodes" : [{"used_GPUs" : {0,1,3}, #{0,1,2,3},
            "cores_per_GPU" : 1,
            "IP": "localhost"   #  num_consumers = multiprocessing.cpu_count() * 2
            }
            ]
}
]
