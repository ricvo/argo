# add here few words about what is the purpose of this experiment
# keep only one experiment per file

##############################################################
[
{
"dataName" : "GTSRB",
"vect" : False  # False if starting with convolutional, True will give the dataset already vectorialized (reshaped -1)
},
{

"model" : ["VAE.VAE"], #"VAE_IAF.VAE_IAF"

"stochastic" : [2],
"stochastic_noise_param" : [0.0, 0.1, 0.2, 0.3, 0.4], #0, ,0.00001,0.001,0.1,1
"denoising" : 1,


"batch_size_train" : [16],
"batch_size_eval" : [16],


"optimizer":  [ ("AdamOptimizer", {"learning_rate" :
                                        (mlr,
                                        "exponential_decay", {"learning_rate" : ilr,
                                                              "decay_steps" : ds, # total train samples: TOT. TOT/BATCH_SIZE = SE steps per epoch
                                                              "decay_rate" : 0.9,
                                                              "staircase" : True
                                                             }
                                         ),
                                  "beta1" : 0.9,
                       			  "beta2" : 0.999})
                   for mlr, ilr, ds in [(1e-5, 1e-3, 20000)] #[(1e-3, 2000), (1e-4, 3000)]
                   ],

"grad_clipping" : ("clip_by_global_norm", {"value" : 1e4}),

"cost_function": [
                  ("ELBO", {"beta" : 1.0,
		            "warm_up_method" : ("warm_up", {"epoch" : 50})})
		  ],

"samples" : [10], # 1 or more
"covariance_parameterization" : "softplus", # "exp" or "softplus"

"network_architecture" : [{
        "encoder" : [
	    ("VGGBlock", {"channels" : 32, "kernel_shape" : 3, "prob_drop": 0.1}, 0),
 	    ("VGGBlock", {"channels" : 64, "kernel_shape" : 3, "prob_drop": 0.1, 'linear_last' : 512}, 0),

        ("GaussianDiagonal", {"output_size" : lsize,
                              "module_tuple" : ("Linear", {}),
                               "contractive_regularizer" : creg,
				              },
				              0)
        ],

        "decoder" : [
        ("ConvDec", {
                    "linear_first" : {"sizes" : [128 * 8 * 8], "reshape" : (8, 8, 128)},
                    "channels" : dec_channels,
                    "kernel_shape" : 3,
                    "final_activation" : True
                    },
                    0
         ),
         output_distribution
         ]
         }


	 

	    for lsize in [100] #, 64]
	    for dec_channels in [[64, 64, 32, 32, 1]]
#	    for scale in [0.1] #, 0.1, 0.01, 0.001, 0.0001, 0.00001]
	    for creg in [
                        None,
#                        ("geometric_contractive_regularizer",
#                                                            {
#                                                            "scale" : scale,
#                                                            })
                    ]

	    for rectuple in [
                        ("Conv2D", {"kernel_shape" : 3}),
#                         ("Linear", {})
                        ]
        for mincov in [1e-5]
	    for output_distribution in [
#                                    ("LogitNormalDiagonalPlusMinusOne", {"module_tuple" : rectuple,
#                                                                         "minimal_covariance": mincov,
#                                                                         "clip_value" : 1e-7}, 0),
                                    ("GaussianDiagonalPlusMinusOne", {"module_tuple" : rectuple,
                                                                         "minimal_covariance": mincov}, 0)
                                    ]
        ],


"weights_reg" : [("contrib.layers.l2_regularizer", {"scale" : 1e-4})],
"bias_reg" : [("contrib.layers.l2_regularizer",    {"scale" : 1e-4})],

"weights_init" : [("contrib.layers.xavier_initializer", {})], # ("truncated_normal_initializer", {"stddev" : 0.02})],  # !!! truncated normal
"bias_init" : [("constant_initializer", {'value' : 0.1})], #   ("constant_initializer", {'value' : 0.0})],

"activation" : ["relu"],  #"relu"
"epochs" : 300,

},
{
"check_ops" : 0,

# choose steps or epochs
"time_reference" : "epochs",

# how often to log stats (txt) and save summaries (related to the stats)
"stats_period" : 1,

# choose to save the model every n steps
"save_model" : 1,
"save_model_period" : 50,
"save_max_to_keep" : 5,

# how often to save other specific summaries
"save_summaries" : 0,
"save_summaries_period" : 10,

# skips the first k stats for the plot
"plot_offset" : 1,


"GradientsHook" : {"period" : 10},

"ImagesInputHook" : {"period" : 50,
                     "how_many" : 18,
                     "n_images_columns" : 6,
                     "until" : 2},

"ImagesReconstructHook" : {"period" : 50,
                           "n_images_columns" : 18,
                           "images_indexes" : {
                                                 "train" : [0,100,200,300,400,500,50,150,250,350,450,550],
                                                 "validation" : [0,100,200,300,400,500,50,150,250,350,450,550],
                                                 },
                            },

"ImagesGenerateHook" : {"period" : 50,
                        "n_images_columns" : 12,
                        "n_gen_samples" : 36
                       },

"TwoDimPCALatentVariablesHook" : {"period" : 50,
                                  },

"PCALatentVariablesHook" : {"period" : 50,
                             },


"ImportanceSamplingHook" : [{"period" : 50,
                                "n_samples" : [1, 100],
                                "batch_size" : 10,
                                "repetitions" : 1
                       	   }],

#"FrechetInceptionDistanceHook" : [{"period" : 50,
#				   "n_batches" : 25
#				  },
#				  {"period" : 50,
#				   "n_batches" : 25,
#				   "pb" : "/home/luigi/prediction/natural/MNIST-c-st0/FF-cCE-st0-stp0-bs32-trGD_lr0.01-cNo-nD200_D200_D10-cpS-aR-wix-bic0.1-r0/saved_models/frozen_graph.pb",
#				   "id" : "MNIST",
#				   "input_tensor" : "inputs:0",
#				   "output_tensor" : "ff_network/network/features:0"
#				  },		  		  
#				  ],


"VAELinearInterpolationHook" : {"period" : 50,
				"n_images" : 15,
				"images_indexes" : {
							"train" : [(0,50), (100,230), (200,330), (300,430), (400,530)],
							"validation": [(0,51), (100,230), (200,330), (300,430), (400,530)]  								 
						   },
				},

#"LatentVarsClassificationHook" : {"period" : 50,
#			          "learning_rate" : 0.001,
#                                  "steps" : 30000,
#				  "repetitions" : 2
#                       	      	 },


#"LogpImportanceSamplingHook" : {"period" : 50,
#		       	        "n_samples" : [1,10],
#		     		"batch_size" : 100,
#				"repetitions" : 2
#                       	       },
    
"dirName" : "/data1/traffic_correct-split_models",

"seed" : 0,
"runs" : 1,

"nodes" : [{"used_GPUs" : [0,1,2,3,5],
            "cores_per_GPU" : 3,
	    "IP": "localhost"   #  num_consumers = multiprocessing.cpu_count() * 2
	   }
	   ],

}
]
