
# add here few words about what is the purpose of this experiment
# keep only one experiment per file

##############################################################
[
{
"dataName" : "NSynth",
"stochastic" : 0,
"label": "note_str",
#"shuffle_buffer" : 4000,
},
{
"model" : "WavenetVAE.WavenetVAE",
"stochastic" : [0],
"stochastic_noise_param" : [0], #[0.03], #0, ,0.00001,0.001,0.1,1
"denoising" : [0],

"optimizer": [("AdamOptimizer", {"learning_rate" : lr,
	                         "beta1": 0.9,
                      		 "beta2":0.999}) for lr in [0.0002]],

"grad_clipping" : ("clip_by_global_norm", {"value" : 7.0}), # NB not implemented in the filename

"cost_function": [
                  ("WavenetELBO", {"beta" : 1.0,
		            #"warm_up_method" : ("warm_up", {"epoch" : 5})})],
		            "warm_up_method" : None})],

"batch_size_train" : 4,
"batch_size_eval" : 4,

"network_architecture" : [{"num_layers_per_stage": 5,
                         "num_layers": 5,
                         "filter_length": 3,
                         "d_hidden_channels": 512,
                         "hop_length": hopl,
                         "e_hidden_channels": 128,
                         "skip_channels": 256,
                         "latent_channels": ch_z,
						 "variational_layer": vl,
						 "n_z_samples":1,
                           'learn_prior': False,
                           'upsample_encoding': False,
                           "p_dropout_decoder_tf": 0,
                           "dim_reduction": ['avg_pool', 'max_pool', 'conv', 'linear'][0],
                            "alpha_rescale": 1.0,
                           }
                                for hopl in [512] for ch_z in [2] for vl in [["GaussianTriDiagonal", "GaussianDiagonal", "GaussianTriDiagonalPrecision"][1]] ],

"epochs" : 1,

},
{
"check_ops" : 0,

# choose steps or epochs
"time_reference" : "steps",

# how often to log stats (txt) and save summaries (related to the stats)
"stats_period" : 1,

# choose to save the model every n steps
"save_model" : 1,
"save_model_period" : 100,

# how often to save other specific summaries
"save_summaries" : 1,
"save_summaries_period" : 10,

# skips the first k stats for the plot
"plot_offset" : 5,


# "WavReconstructHook" : {  "period" : 500,
#                           "sample_indices_by_dataset" : {
#                                             "train" : [0,1100,2200,3300,4400,5500],
#                                             "validation" : [0,1100,2200,3300,4400,5500],
#                                             },
#                         },

"WavGenerateHook" : {  "period" : 1,
                          "sample_indices_by_dataset" : {
                                            "train" : [0,1100,2200,3300,4400,5500],
                                            "validation" : [0,1100,2200,3300,4400,5500],
                                            },
                          "fast_gen" : True,  # use fast_generation wavenet for reconstruction without teacher forcing
                          "debug_fast_gen" : False,  # use fast_generation wavenet with the true input shifted and quantized to reconstruct with teacher forcing and check the FastGen network

                        },

#"TwoDimPCALatentVariablesHook" : {"period" : 20,
#                                  },

#"PCALatentVariablesHook" : {"period" : 10,
#                             },


"dirName" : "/data1/rcolt/NSynth",

"seed" : 0,
"runs" : 1,

"nodes" : [{"used_GPUs" : [0],
            "cores_per_GPU" : 1,
            "IP": "localhost"   #  num_consumers = multiprocessing.cpu_count() * 2
            }
            ]


}
]
